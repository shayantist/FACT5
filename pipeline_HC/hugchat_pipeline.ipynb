{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCUhIrM43cdB",
        "outputId": "98b29747-119c-49d8-be05-41606598c851"
      },
      "outputs": [],
      "source": [
        "# # For transformer models\n",
        "# !pip install -q accelerate\n",
        "# # !pip install -q bitsandbytes\n",
        "# !pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "# # !pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "# # For sentence similarity\n",
        "# !pip install -q sentence_transformers\n",
        "\n",
        "# # For web queries\n",
        "# !pip install -q googlesearch-python\n",
        "\n",
        "# # For Retrieval Augmentated Generation (RAG) since HF doesn't have great support for it\n",
        "# !pip install -q langchain chromadb\n",
        "\n",
        "# # For using the Unofficial HuggingChat Python API: https://github.com/Soulter/hugging-chat-api\n",
        "# !pip install -q hugchat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import dotenv\n",
        "\n",
        "# Add the parent directory to sys.path so we can import other py files\n",
        "sys.path.append('../')\n",
        "\n",
        "# Set environment variables\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "# Hide warnings cuz they're annoying\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load examples from JSON file\n",
        "with open('../data/examples.json', 'r') as f:\n",
        "    examples = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xON-OssXfjFq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using model: mistralai/Mixtral-8x7B-Instruct-v0.1\n"
          ]
        }
      ],
      "source": [
        "# HuggingChat API Setup\n",
        "from hugchat import hugchat\n",
        "from hugchat.login import Login\n",
        "\n",
        "# Log in to huggingface and grant authorization to huggingchat\n",
        "cookie_path_dir = \"./cookies/\" # NOTE: trailing slash (/) is required to avoid errors\n",
        "sign = Login(os.environ.get('HF_EMAIL'), os.environ.get('HF_PASSWORD'))\n",
        "cookies = sign.login(cookie_dir_path=cookie_path_dir, save_cookies=True)\n",
        "\n",
        "# Create your ChatBot\n",
        "chatbot = hugchat.ChatBot(cookies=cookies.get_dict())  # or cookie_path=\"usercookies/<email>.json\"\n",
        "# Get the available models (not hardcore)\n",
        "models = chatbot.get_available_llm_models()\n",
        "model_idx = 3\n",
        "chatbot.switch_llm(model_idx)\n",
        "print(f'Using model: {models[chatbot.get_active_llm_index()]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "efOMk3zSljAZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
          ]
        }
      ],
      "source": [
        "from prompts import claim_atomization_template\n",
        "from utils.nlp_utils import select_best_examples\n",
        "from utils.code_utils import multiline_string_to_list\n",
        "\n",
        "def generate_atomic_claims(statements, num_examples=3):\n",
        "    \"\"\"\n",
        "    Generates atomic claims for the input statements.\n",
        "\n",
        "    Args:\n",
        "        claim (str): The input statements.\n",
        "        num_examples (int, optional): The number of few-shot examples to include in the prompt. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated atomic claims.\n",
        "    \"\"\"\n",
        "    if num_examples > 0: # Populate the prompt with few-shot examples (w/ proper formatting)\n",
        "        examples_text = \"\"\n",
        "        best_examples = select_best_examples(statements, examples[\"claim_atomization_examples\"], \"statement\", num_examples)\n",
        "\n",
        "        # Add each example to the prompt\n",
        "        for example in best_examples:\n",
        "            examples_text += f\"Statements: {example['statement']}\\n\"\n",
        "            examples_text += f\"Atomic Claims: {example['atomic_claims']}\\n\"\n",
        "\n",
        "        # Finally, fill in the prompt template with the examples and the input statements\n",
        "        prompt = claim_atomization_template.format(examples=examples_text.strip(), statements=statements).strip()\n",
        "    else: # Otherwise leave the examples section of the prompt template blank and only include the input statements\n",
        "        prompt = claim_atomization_template.format(examples=\"\", statements=statements.strip()).strip()\n",
        "\n",
        "    # # Print the entire prompt for debugging purposes\n",
        "    # print(prompt)\n",
        "\n",
        "    # Generate atomic claims using the HuggingChat API\n",
        "    output_text = str(chatbot.chat(prompt))\n",
        "\n",
        "    # Extract only the list of claims from the model's output\n",
        "    # Assuming output format directly returns Python list\n",
        "    try:\n",
        "        output_text = output_text.split('Atomic Claims:')[-1].strip()\n",
        "        atomic_claims = multiline_string_to_list(output_text)\n",
        "        # POST-PROCESSING ERROR HANDLING: If list contains lists, return a flattened list\n",
        "        if isinstance(atomic_claims[0], list):\n",
        "            atomic_claims = [item for sublist in atomic_claims for item in sublist]\n",
        "        return atomic_claims\n",
        "    except:\n",
        "        print(f\"Error parsing model output: {output_text}\\nRetrying...\")\n",
        "        return generate_atomic_claims(statements, num_examples)\n",
        "\n",
        "# # Example usage\n",
        "# statements = '''\n",
        "# \"In New York, there are no barriers to law enforcement to work with the federal government on immigration laws, and there are 100 crimes where migrants can be handed over.\"\n",
        "# '''\n",
        "# atomic_claims = generate_atomic_claims(statements)\n",
        "# print(f'Statement: {statements}')\n",
        "# print(f'Atomic Claims: {atomic_claims}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iqsh52A1tqOM"
      },
      "outputs": [],
      "source": [
        "## Question Generation\n",
        "from prompts import question_generation_template\n",
        "\n",
        "def generate_questions(claim, num_examples=3):\n",
        "    \"\"\"\n",
        "    Generates questions to verify the factuality of the input claim.\n",
        "\n",
        "    Args:\n",
        "        claim (str): The input claim.\n",
        "        num_examples (int, optional): The number of few-shot examples to include in the prompt. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated questions.\n",
        "    \"\"\"\n",
        "    if num_examples > 0: # Populate the prompt with few-shot examples (w/ proper formatting)\n",
        "        examples_text = \"\"\n",
        "        best_examples = select_best_examples(claim, examples[\"question_generation_examples\"], \"claim\", num_examples)\n",
        "\n",
        "        # Add each example to the prompt\n",
        "        for example in best_examples:\n",
        "            examples_text += f\"Claim: {example['claim']}\\n\"\n",
        "            examples_text += f\"Questions: {example['questions']}\\n\"\n",
        "\n",
        "        # Finally, fill in the prompt template with the examples and the input claim\n",
        "        prompt = question_generation_template.format(examples=examples_text.strip(), claim=claim).strip()\n",
        "    else: # Otherwise leave the examples section of the prompt template blank and only include the input claim\n",
        "        prompt = question_generation_template.format(examples=\"\", claim=claim).strip()\n",
        "\n",
        "    # Print the entire prompt for debugging purposes\n",
        "    # print(prompt)\n",
        "\n",
        "    # Generate questions using the HuggingChat API\n",
        "    output_text = str(chatbot.chat(prompt))\n",
        "\n",
        "    # Extract only the list of questions from the model's output\n",
        "    try:\n",
        "        # Assuming output format directly returns Python list\n",
        "        questions = multiline_string_to_list(output_text.split('Questions:')[-1].strip())\n",
        "        return questions\n",
        "    except:\n",
        "        print(f\"Error parsing model output: {output_text}\\nRetrying...\")\n",
        "        return generate_questions(claim, num_examples)\n",
        "    \n",
        "# # Example usage for question generation\n",
        "# claim_question = dict()\n",
        "# for i, claim in enumerate(atomic_claims):\n",
        "#   questions = generate_questions(claim)\n",
        "#   claim_question[claim] = questions\n",
        "#   print(f\"Claim: {claim}\")\n",
        "#   print(f\"Questions: {claim_question[claim]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aCYr74RW3kul"
      },
      "outputs": [],
      "source": [
        "## Web Querying & Scraping\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "SOURCE_BLACKLIST = ['politifact.org', 'factcheck.org', 'snopes.com']\n",
        "\n",
        "def extract_website_name(url):\n",
        "    \"\"\"Extracts the website name from a given URL using regex\"\"\"\n",
        "    match = re.search(r'(?P<url>https?://[^\\s]+)', url)\n",
        "    if match:\n",
        "        url = match.group('url')\n",
        "        return url.split('//')[1].split('/')[0].lower().replace('www.', '')\n",
        "    return None\n",
        "\n",
        "def scrape_text_from_website(url):\n",
        "    \"\"\"Scrapes text and metadata from a given website URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Remove script and style tags\n",
        "            for script in soup([\"script\", \"style\"]):\n",
        "                script.decompose()\n",
        "\n",
        "            # Extract all text from the website\n",
        "            text = soup.get_text()\n",
        "\n",
        "            # Clean up whitespace\n",
        "            text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "            return text\n",
        "        else:\n",
        "            # print(f\"Failed to retrieve content from the URL: {url}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        # print(f\"Error during website scraping: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_search_results(question, scrape_website=False):\n",
        "    \"\"\"\n",
        "    Fetches search results for a given question using an API.\n",
        "\n",
        "    Args:\n",
        "        question (str): The question to search for.\n",
        "        scrape_website (bool, optional): Whether to scrape the website content. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of organic search results.\n",
        "    \"\"\"\n",
        "    api_key = os.environ.get(\"SERPER_API_KEY\")\n",
        "\n",
        "    headers = {\n",
        "        \"X-API-KEY\": api_key,\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    payload = json.dumps({\"q\": question})\n",
        "    try:\n",
        "        response = requests.post(\"https://google.serper.dev/search\", headers=headers, data=payload)\n",
        "        result = json.loads(response.text)\n",
        "\n",
        "        # Extract the organic search results and transform them into our desired format\n",
        "        results = []\n",
        "        for item in result['organic']:\n",
        "            # ALSO while iterating through the results, remove any websites on our source blacklist\n",
        "            source = extract_website_name(item.get('link', ''))\n",
        "            if source in SOURCE_BLACKLIST: continue\n",
        "            website_text = scrape_text_from_website(item.get('link', '')) if scrape_website else item.get('snippet', '')\n",
        "            if website_text is None or website_text == '': # if we failed to scrape the website, use the snippet\n",
        "                website_text = item.get('snippet', '')\n",
        "            results.append({\n",
        "                \"title\": item.get('title', ''),\n",
        "                \"source\": source,\n",
        "                \"date_published\": item.get('date', ''),\n",
        "                \"relevant_excerpt\": item.get('snippet', ''),\n",
        "                \"text\": website_text,\n",
        "                \"search_position\": item.get('position', -1),\n",
        "                \"url\": item.get('link', ''),\n",
        "            })\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to fetch information: {e}\")\n",
        "        return []\n",
        "\n",
        "# # Example usage:\n",
        "# question = question = '''\n",
        "# In New York, are there barriers to law enforcement to work with the federal government on immigration laws?\n",
        "# '''\n",
        "# search_results = fetch_search_results(question)\n",
        "# search_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y0wLmC-73F5C"
      },
      "outputs": [],
      "source": [
        "## Retrieval Augmented Generation (RAG) Retriever\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import torch\n",
        "\n",
        "import copy\n",
        "\n",
        "# Initialize embedding model for retrieval (sentence similarity)\n",
        "BATCH_SIZE = 32\n",
        "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "retriever_model_id='sentence-transformers/all-MiniLM-L6-v2'\n",
        "retriever_model = HuggingFaceEmbeddings(\n",
        "    model_name=retriever_model_id,\n",
        "    model_kwargs={'device': device},\n",
        "    encode_kwargs={'device': device, 'batch_size': BATCH_SIZE},\n",
        ")\n",
        "\n",
        "def retrieve_relevant_documents_using_rag(search_results, content_key, question, chunk_size=512, chunk_overlap=128, top_k=10):\n",
        "    \"\"\"\n",
        "    Takes in search results and a query question, processes and splits the documents,\n",
        "    and retrieves relevant documents using a RAG approach.\n",
        "\n",
        "    Args:\n",
        "        search_results (list of dict): A list of dictionaries containing web-scraped data.\n",
        "        question (str): The query question for retrieving relevant documents.\n",
        "        content_key (str): The key in the dictionary containing the text content.\n",
        "        chunk_size (int): The maximum size of the text chunks.\n",
        "        chunk_overlap (int): The overlap between consecutive text chunks.\n",
        "        top_k (int): The number of relevant documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of relevant document chunks.\n",
        "    \"\"\"\n",
        "    # Create LangChain documents from search results\n",
        "    documents = []\n",
        "    for result in search_results:\n",
        "        page_content = result.pop(content_key, None)  # Extract the text content, remaining keys are metadata\n",
        "        if page_content is not None:\n",
        "            documents.append(Document(page_content=page_content, metadata=result))\n",
        "\n",
        "    # Split documents into smaller chunks (if needed, based on document size)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "    )\n",
        "    split_documents = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Initialize ChromaDB vector store to index the document chunks\n",
        "    db = Chroma.from_documents(\n",
        "        documents=split_documents,\n",
        "        embedding=retriever_model,\n",
        "    )\n",
        "\n",
        "    # Retrieve the most relevant chunks for the given question\n",
        "    top_k = min(top_k, len(split_documents))  # Ensure we don't request more documents than available\n",
        "    relevant_docs = db.similarity_search(question, k=top_k)\n",
        "\n",
        "    return relevant_docs\n",
        "\n",
        "# question = '''\n",
        "# In New York, are there barriers to law enforcement to work with the federal government on immigration laws?\n",
        "# '''\n",
        "# relevant_docs = retrieve_relevant_documents_using_rag(search_results, 'text', question)\n",
        "# relevant_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6gOyIez85oP4"
      },
      "outputs": [],
      "source": [
        "## RAG-based Question Answering\n",
        "from prompts import answer_synthesis_template\n",
        "\n",
        "def synthesize_answer(relevant_docs, question, return_sources=True):\n",
        "    \"\"\"\n",
        "    Synthesizes an answer to a given question using the relevant documents.\n",
        "\n",
        "    Args:\n",
        "        relevant_docs (list of dict): A list of relevant document chunks.\n",
        "        question (str): The question to answer.\n",
        "\n",
        "    Returns:\n",
        "        str: The synthesized answer.\n",
        "    \"\"\"\n",
        "    # Format the relevant documents for the prompt\n",
        "    documents_text = \"\"\n",
        "    for doc in relevant_docs:\n",
        "        documents_text += f\"Title: {doc.metadata.get('title', '')}\\n\"\n",
        "        documents_text += f\"URL: {doc.metadata.get('url', '')}\\n\"\n",
        "        documents_text += f\"Text: {doc.page_content.strip()}\\n\"\n",
        "        documents_text += f\"Date Published: {doc.metadata.get('date_published', '')}\\n\\n\"\n",
        "\n",
        "    # Fill in the prompt template with the relevant documents and the question\n",
        "    prompt = answer_synthesis_template.format(documents=documents_text.strip(), question=question).strip()\n",
        "    prompt = prompt.replace('\\n\\n\\n', '\\n')\n",
        "\n",
        "    # Print the entire prompt for debugging purposes\n",
        "    # print(prompt)\n",
        "\n",
        "    # Generate the answer using the HuggingChat API\n",
        "    output_text = str(chatbot.chat(prompt))\n",
        "\n",
        "    # Extract the answer and sources separately from the model's output\n",
        "    try:\n",
        "        answer = output_text.split('Answer:')[-1].split('Sources:')[0].strip()\n",
        "        sources = output_text.split('Sources:')[-1].strip()\n",
        "        if return_sources: return answer, sources\n",
        "        return answer\n",
        "    except:\n",
        "        print(f\"Error parsing model output: {output_text}\\nRetrying...\")\n",
        "        return synthesize_answer(relevant_docs, question, return_sources)\n",
        "    \n",
        "# # Example usage for RAG-based question answering\n",
        "# # answer, sources = synthesize_answer(relevant_docs, question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X_bLNrBT6NaR"
      },
      "outputs": [],
      "source": [
        "## Claim Classification\n",
        "from prompts import claim_classification_template\n",
        "\n",
        "def classify_claim(claim, questions, answers, return_reasoning=True):\n",
        "    \"\"\"\n",
        "    Uses a chain-of-thought approach to classify the original claim as true or false based on the answers to generated questions.\n",
        "\n",
        "    Args:\n",
        "        claim (str): The original claim.\n",
        "        questions (list): List of questions related to the claim.\n",
        "        answers (list): List of answers corresponding to the questions.\n",
        "\n",
        "    Returns:\n",
        "        str: The conclusion whether the claim is true or false with reasoning.\n",
        "    \"\"\"\n",
        "    # Format the questions and answers into a single string\n",
        "    questions_and_answers = \"\"\n",
        "    for question, answer in zip(questions, answers):\n",
        "        questions_and_answers += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
        "\n",
        "    # Fill in the prompt template with the claim and formatted questions and answers\n",
        "    prompt = claim_classification_template.format(claim=claim, questions_and_answers=questions_and_answers)\n",
        "\n",
        "    # Print the entire prompt for debugging purposes\n",
        "    # print(prompt)\n",
        "\n",
        "    # Generate the classification using the HuggingChat API\n",
        "    output_text = str(chatbot.chat(prompt))\n",
        "\n",
        "    # Extract the verdict and reasoning separately from the model's output\n",
        "    try:\n",
        "        verdict = output_text.split('Verdict:')[-1].split('Reasoning:')[0].strip()\n",
        "        reasoning = output_text.split('Reasoning:')[-1].strip()\n",
        "        if return_reasoning: return verdict, reasoning\n",
        "        return verdict\n",
        "    except:\n",
        "        raise ValueError(f\"Error parsing model output: {output_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tlX892CznuzR"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "def generate_fact_score(verdicts):\n",
        "    label = None\n",
        "    perc_unverified = 0\n",
        "    v_cleaned = verdicts\n",
        "    if 'Unverifiable' in verdicts:\n",
        "        v_cleaned = verdicts[:]\n",
        "        v_cleaned.remove('Unverifiable')\n",
        "        perc_unverified = Counter(verdicts)['Unverifiable'] / len(verdicts)\n",
        "    perc_true = Counter(verdicts)['True'] / len(verdicts)\n",
        "    perc_false = Counter(verdicts)['False'] / len(verdicts)\n",
        "    perc = [perc_true, perc_false, perc_unverified]\n",
        "    winner = np.argwhere(perc == np.amax(perc))\n",
        "\n",
        "    if len(winner) == 3: # three-way tie\n",
        "        label = \"Unverifiable\"\n",
        "\n",
        "    elif len(winner) == 2: # two-way tie\n",
        "        if 0 in winner and 1 in winner: # half true\n",
        "            label = 'Half True'\n",
        "        elif 0 in winner and 2 in winner: # true & unverifable\n",
        "            label = \"Unverifiable\"\n",
        "        elif 1 in winner and 2 in winner: # false & unverifable\n",
        "            label = \"Unverifiable\"\n",
        "\n",
        "    elif len(winner) == 1:\n",
        "        if 0 in winner:\n",
        "            if perc_true == 1: # all true\n",
        "                label = \"True\"\n",
        "            elif Counter(v_cleaned)['True'] / len(v_cleaned) > 0.5: # mostly true\n",
        "                label = \"Mostly True\"\n",
        "            else:\n",
        "                label = 'Unverifiable'\n",
        "        elif 1 in winner:\n",
        "            if perc_false == 1: # all false\n",
        "                label = \"Pants on Fire\"\n",
        "            elif Counter(v_cleaned)['False'] / len(v_cleaned) > 0.5: # mostly false\n",
        "                label = \"Mostly False\"\n",
        "            else:\n",
        "                label = 'Unverifiable'\n",
        "        elif 2 in winner:\n",
        "            label = 'Unverifiable'\n",
        "    return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PGQWeZyfCnC8"
      },
      "outputs": [],
      "source": [
        "def verify_statement_hugchat(statement, num_examples=0):\n",
        "    \"\"\"\n",
        "    Runs the entire fact-checking pipeline for the input claim.\n",
        "\n",
        "    Args:\n",
        "        statement (str): The input statement(s).\n",
        "        num_examples (int, optional): The number of few-shot examples to include in the prompts. Defaults to 0.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the verdicts, output dictionary, fact score, and reasoning for the claim.\n",
        "    \"\"\"\n",
        "    # Write out the whole pipeline and be verbose about what's happening (print out the steps)\n",
        "    print(\"Statement:\", statement)\n",
        "\n",
        "    atomic_claims = generate_atomic_claims(statement, num_examples)\n",
        "    print(\"Atomic Claims generated:\", len(atomic_claims))\n",
        "\n",
        "    output_dict = []  # List to store all the info for each atomic claim (claim, questions, answers, verdict, reasoning)\n",
        "    verdicts = []\n",
        "    reasonings = []\n",
        "\n",
        "    for i, claim in enumerate(atomic_claims, start=1):\n",
        "        print(f\"Processing Atomic Claim {i}/{len(atomic_claims)}:\")\n",
        "        print(\"\\tClaim:\", claim)\n",
        "\n",
        "        claim_output = {}\n",
        "        claim_output['claim'] = claim\n",
        "\n",
        "        questions = generate_questions(claim, num_examples)\n",
        "        print(\"\\tQuestions generated:\", len(questions))\n",
        "\n",
        "        claim_output['qa-pairs'] = {}\n",
        "        claim_output['qa-pairs']['questions'] = questions\n",
        "        answers = []\n",
        "        sources = []\n",
        "        for j, question in enumerate(questions, start=1):\n",
        "            print(f\"\\t\\tQuestion {j}/{len(questions)}:\", question)\n",
        "\n",
        "            search_results = fetch_search_results(question, scrape_website=True)\n",
        "            relevant_docs = retrieve_relevant_documents_using_rag(search_results, 'relevant_excerpt', question)\n",
        "\n",
        "            answer, source = synthesize_answer(relevant_docs, question)\n",
        "            answers.append(answer)\n",
        "            sources.append(source)\n",
        "\n",
        "            print(f\"\\t\\tAnswer {j}/{len(questions)}:\", answer)\n",
        "            # print(f\"\\t\\tSources {j}:\", source)\n",
        "\n",
        "        claim_output['qa-pairs']['answers'] = answers\n",
        "        claim_output['qa-pairs']['sources'] = sources\n",
        "\n",
        "        verdict, reasoning = classify_claim(claim, questions, answers)\n",
        "        verdicts.append(verdict)\n",
        "        reasonings.append((claim, reasoning))\n",
        "        claim_output['verdict'] = verdict\n",
        "        claim_output['reasoning'] = reasoning\n",
        "\n",
        "        print(\"\\tVerdict:\", verdict)\n",
        "        print(\"\\tReasoning:\", reasoning)\n",
        "\n",
        "        output_dict.append(claim_output)\n",
        "\n",
        "    print(\"\\nVerdicts:\", verdicts)\n",
        "\n",
        "    fact_score = generate_fact_score(verdicts)\n",
        "    print(\"\\nFact Score:\", fact_score)\n",
        "\n",
        "    reasoning = '\\n'.join([\"Claim: \" + item[0] + \"\\nReasoning: \" + item[1] + \"\\n\" for item in reasonings])\n",
        "\n",
        "    return verdicts, output_dict, fact_score, reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A8yjCIO97JEx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     “The National Guard in the HISTORY of its life...\n",
              "1     \"On Jan. 6, 2021, U.S. Capitol 'protestors car...\n",
              "2         \"Not even one rocket (from Iran) hit Israel.\"\n",
              "3     \"326,000 migrants were flown to Florida with t...\n",
              "4     \"Crime is down in Venezuela by 67% because the...\n",
              "5     \"In New York, there are no barriers to law enf...\n",
              "6     \"Speaking of semiconductor industry jobs, \"Kno...\n",
              "7     \"Starting in 2025 \"no matter what your total b...\n",
              "8     “Tens of thousands of auto jobs were lost nati...\n",
              "9     \"The current Congress is “the least productive...\n",
              "10    \"Video shows “New York Governor Kathy Hochul b...\n",
              "11    \"We’ve had 12 elections in 24 years in Wiscons...\n",
              "12    After a 2022 law, “The vast majority of colleg...\n",
              "13    \"Insulin for Medicare beneficiaries \"was costi...\n",
              "14    “Support for Roe is higher today in America th...\n",
              "15    \"The 2022 CHIPS and Science Act “attracted $64...\n",
              "16              “It is a fact that Obama created ISIS.”\n",
              "17    \"Millions of Arizonans will soon live under an...\n",
              "18    \"In Michigan, radical, left Democrat governor ...\n",
              "19    \"[Rep. Adam Schiff] won’t tell you that he jus...\n",
              "20    \"I have to say, there are a lot of things that...\n",
              "21    \"Pharmaceutical medicine has its place, but no...\n",
              "22    \"Former U.S. President Donald Trump stated tha...\n",
              "23    \"Billionaire investor and philanthropist, Geor...\n",
              "24    \"President Donald Trump \"just told TIME Magazi...\n",
              "25    \"Joe Biden graduated 76th academically in a cl...\n",
              "26    \"Only two presidents in American history left ...\n",
              "27    \"The top donor to a major super PAC supporting...\n",
              "28    \"Now, if I don’t get elected, it’s going to be...\n",
              "29    \"U.S. President Joe Biden is the first preside...\n",
              "30    \"In February 2024, Nikki Haley lost the Nevada...\n",
              "31    \"U.S. President Joe Biden is the only presiden...\n",
              "32    \"Former U.S. President Donald Trump is the fir...\n",
              "33    \"Former U.S. President Donald Trump's margin o...\n",
              "34    \"U.S. Republican 2024 presidential candidate V...\n",
              "35    \"Have you had to cancel or rethink any upcomin...\n",
              "36    \"Unlike the Democrats, who are KILLING SOCIAL ...\n",
              "37    \"We know that President Biden didn’t just crea...\n",
              "38    \"You remember they [Iran] fired. They hit one ...\n",
              "39    \"Look, folks, you know how many billionaires w...\n",
              "40    \"We had the best unemployment rates ever. And ...\n",
              "41    \"House Republicans took numerous votes that wo...\n",
              "42    \"We didn’t sell any land to the Chinese. But, ...\n",
              "43    \"The climate change agenda is a hoax … The rea...\n",
              "44    \"How are we supposed to get our girls used to ...\n",
              "45    \"China’s eyes and ears — dangerously close, to...\n",
              "46    \"Hundreds of people on our terrorist watch lis...\n",
              "47    \"This trial that I have now, that’s a Biden tr...\n",
              "48    \"President Biden is the first candidate in his...\n",
              "49    \"Dollar Tree, Walgreens, Macy’s, Foot Locker, ...\n",
              "Name: statement, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_dir = '../data/' # TODO: modify this to the correct path for you!\n",
        "filename = 'pilot.csv'\n",
        "full_path = os.path.join(base_dir, filename)\n",
        "df = pd.read_csv(full_path)\n",
        "\n",
        "df['statement'] = df['statement'].astype(str)\n",
        "\n",
        "df['statement'][:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "save_filename = '../pkl_for_final_dataset/fact_check_samples_cohere.pkl'\n",
        "if os.path.exists(save_filename):\n",
        "    fact_check_samples = pickle.load(open(save_filename, 'rb'))\n",
        "else: \n",
        "    fact_check_samples = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9_keiIR2qIya",
        "outputId": "139bd4a4-a591-4bf5-fb9c-98d147197315"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b97bd2f1746247eb85f022af4b7c686d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statement: \"Only two presidents in American history left office with fewer jobs than when they entered office. Herbert Hoover and yes, Donald Herbert Hoover Trump.\"\n",
            "Atomic Claims generated: 3\n",
            "Processing Atomic Claim 1/3:\n",
            "\tClaim: Two US presidents left office with fewer jobs than when they entered.\n",
            "\tQuestions generated: 2\n",
            "\t\tQuestion 1/2: Did Herbert Hoover leave office with fewer jobs than when he started? \n",
            "Failed to fetch information: 'organic'\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected IDs to be a non-empty list, got 0 IDs",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df_subset\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_subset)):\n\u001b[1;32m      6\u001b[0m     statement \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mverify_statement_hugchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     fact_check_samples\u001b[38;5;241m.\u001b[39mappend(result)\n",
            "Cell \u001b[0;32mIn[12], line 40\u001b[0m, in \u001b[0;36mverify_statement_hugchat\u001b[0;34m(statement, num_examples)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mQuestion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(questions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[1;32m     39\u001b[0m search_results \u001b[38;5;241m=\u001b[39m fetch_search_results(question, scrape_website\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_relevant_documents_using_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelevant_excerpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m answer, source \u001b[38;5;241m=\u001b[39m synthesize_answer(relevant_docs, question)\n\u001b[1;32m     43\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(answer)\n",
            "Cell \u001b[0;32mIn[8], line 51\u001b[0m, in \u001b[0;36mretrieve_relevant_documents_using_rag\u001b[0;34m(search_results, content_key, question, chunk_size, chunk_overlap, top_k)\u001b[0m\n\u001b[1;32m     48\u001b[0m split_documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Initialize ChromaDB vector store to index the document chunks\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Retrieve the most relevant chunks for the given question\u001b[39;00m\n\u001b[1;32m     57\u001b[0m top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(top_k, \u001b[38;5;28mlen\u001b[39m(split_documents))  \u001b[38;5;66;03m# Ensure we don't request more documents than available\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/LLMs/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    777\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/LLMs/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    731\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    732\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    733\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    734\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    735\u001b[0m     ):\n\u001b[0;32m--> 736\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/LLMs/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:324\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    319\u001b[0m             embeddings\u001b[38;5;241m=\u001b[39membeddings_without_metadatas,\n\u001b[1;32m    320\u001b[0m             documents\u001b[38;5;241m=\u001b[39mtexts_without_metadatas,\n\u001b[1;32m    321\u001b[0m             ids\u001b[38;5;241m=\u001b[39mids_without_metadatas,\n\u001b[1;32m    322\u001b[0m         )\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/LLMs/lib/python3.10/site-packages/chromadb/api/models/Collection.py:477\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    446\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     (\n\u001b[1;32m    471\u001b[0m         ids,\n\u001b[1;32m    472\u001b[0m         embeddings,\n\u001b[1;32m    473\u001b[0m         metadatas,\n\u001b[1;32m    474\u001b[0m         documents,\n\u001b[1;32m    475\u001b[0m         images,\n\u001b[1;32m    476\u001b[0m         uris,\n\u001b[0;32m--> 477\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/LLMs/lib/python3.10/site-packages/chromadb/api/models/Collection.py:545\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    525\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m     Optional[URIs],\n\u001b[1;32m    544\u001b[0m ]:\n\u001b[0;32m--> 545\u001b[0m     valid_ids \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m     valid_embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    547\u001b[0m         validate_embeddings(\n\u001b[1;32m    548\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     )\n\u001b[1;32m    553\u001b[0m     valid_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    554\u001b[0m         validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/LLMs/lib/python3.10/site-packages/chromadb/api/types.py:228\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ids)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    230\u001b[0m dups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[0;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "df_subset = df[26:50]\n",
        "\n",
        "# print(\"Using HuggingChat model:\", models[model_idx])\n",
        "for index, row in tqdm(df_subset.iterrows(), total=len(df_subset)):\n",
        "    statement = row['statement']\n",
        "    result = verify_statement_hugchat(statement)\n",
        "    fact_check_samples.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(fact_check_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['True'],\n",
              " [{'claim': 'Joe Biden graduated 76th out of 85 students at Syracuse University College of Law in 1968.',\n",
              "   'qa-pairs': {'questions': ['Did Joe Biden graduate from Syracuse University College of Law in 1968?',\n",
              "     \"What was Joe Biden's class rank at Syracuse University College of Law?\",\n",
              "     'Was Joe Biden a student at Syracuse University in the 1960s?'],\n",
              "    'answers': ['Yes, Joe Biden graduated from Syracuse University College of Law in 1968.',\n",
              "     \"Joe Biden's class rank at Syracuse University College of Law was 76th out of 85 students.\",\n",
              "     'Yes, Joe Biden was a student at Syracuse University College of Law in the 1960s, specifically in 1968.'],\n",
              "    'sources': ['[\\n    {\\n        \"text\": \"A rumor said Joe Biden finished 76th in a class of 85 at Syracuse University College of Law in 1968. \\\\\"Did Biden graduate 76th out of a class ...\",\\n        \"url\": \"https://www.yahoo.com/news/fact-check-rumor-says-biden-130000833.html\",\\n        \"date_published\": \"Apr 27, 2024\"\\n    },\\n    {\\n        \"text\": \"Ahead of President-elect Joe Biden\\'s inauguration, learn how the Syracuse College of Law graduate became the university\\'s most notable ...\",\\n        \"url\": \"https://www.thenewshouse.com/off-campus/politics/syracuse-law-school-joe-biden-united-states-president/\",\\n        \"date_published\": \"Jan 18, 2021\"\\n    },\\n    {\\n        \"text\": \"Biden Jr. L\\'68 today became the 46th president of the United States. Biden, who received a juris doctor from the College of Law in 1968, is the ...\",\\n        \"url\": \"https://news.syr.edu/blog/2020/11/07/joseph-r-biden-jr-l68-becomes-first-syracuse-university-alumnus-elected-president/\",\\n        \"date_published\": \"Nov 7, 2020\"\\n    },\\n    {\\n        \"text\": \"Biden, who received a juris doctor from the College of Law in 1968, is the ...\",\\n        \"url\": \"https://law.syracuse.edu/wp-content/uploads/VP_Biden_Citation.pdf\",\\n        \"date_published\": null\\n    },\\n    {\\n        \"text\": \"Dean Craig M. Boise. “The time is always right to do what is right” —Rev. Martin Luther King Jr. When Joseph R. Biden Jr. L\\'68 was sworn in as President of ...\",\\n        \"url\": \"https://law.syracuse.edu/alumni-friends/syracuse-law-magazine/law-magazine-archive/stories-book-2021/deans-message/\",\\n        \"date_published\": null\\n    }\\n]',\n",
              "     '[\\n    {\\n        \"text\": \"Joe Biden was 76 out of 85, which is excellent for a school of law the caliber of Syracuse University. His achievement certainly opened some ...\",\\n        \"url\": \"https://www.quora.com/In-what-ways-do-you-think-Joe-Bidens-academic-ranking-at-Syracuse-University-College-of-Law-influenced-his-later-achievements-and-career-trajectory\",\\n        \"date_published\": \"Apr 22, 2024\"\\n    },\\n    {\\n        \"text\": \"A rumor said Joe Biden finished 76th in a class of 85 at Syracuse University College of Law in 1968. \\\\\"Did Biden graduate 76th out of a class ...\",\\n        \"url\": \"https://www.yahoo.com/news/fact-check-rumor-says-biden-130000833.html\",\\n        \"date_published\": \"Apr 27, 2024\"\\n    },\\n    {\\n        \"text\": \"But did you know that his academic performance once placed him 76th out of 85 students at Syracuse University College of Law in 1968? Trueas per ...\",\\n        \"url\": \"https://medium.com/the-truth-chronicles/unveiling-the-truth-where-did-biden-stand-in-his-law-class-at-syracuse-university-in-1968-58d2e4f4f4e3\",\\n        \"date_published\": \"Apr 23, 2024\"\\n    }\\n]',\n",
              "     '[\\n    {\\n        \"text\": \"Joe Biden was 76 out of 85, which is excellent for a school of law the caliber of Syracuse University. His achievement certainly opened some ...\",\\n        \"url\": \"https://www.quora.com/In-what-ways-do-you-think-Joe-Bidens-academic-ranking-at-Syracuse-University-College-of-Law-influenced-his-later-achievements-and-career-trajectory\",\\n        \"date_published\": \"Apr 22, 2024\"\\n    },\\n    {\\n        \"text\": \"A rumor said Joe Biden finished 76th in a class of 85 at Syracuse University College of Law in 1968. \\\\\"Did Biden graduate 76th out of a class ...\",\\n        \"url\": \"https://www.yahoo.com/news/fact-check-rumor-says-biden-130000833.html\",\\n        \"date_published\": \"Apr 27, 2024\"\\n    },\\n    {\\n        \"text\": \"But did you know that his academic performance once placed him 76th out of 85 students at Syracuse University College of Law in 1968? Trueas per ...\",\\n        \"url\": \"https://medium.com/the-truth-chronicles/unveiling-the-truth-where-did-biden-stand-in-his-law-class-at-syracuse-university-in-1968-58d2e4f4f4e3\",\\n        \"date_published\": \"Apr 23, 2024\"\\n    },\\n    {\\n        \"text\": \"Biden Jr. L\\'68 today became the 46th president of the United States. Biden, who received a juris doctor from the College of Law in 1968, is the ...\",\\n        \"url\": \"https://news.syr.edu/blog/2020/11/07/joseph-r-biden-jr-l68-becomes-first-syracuse-university-alumnus-elected-president/\",\\n        \"date_published\": \"Nov 7, 2020\"\\n    }\\n]']},\n",
              "   'verdict': 'True',\n",
              "   'reasoning': \"The answers to all three questions support the claim. The first answer confirms that Joe Biden graduated from Syracuse University College of Law in 1968. The second answer states that Biden's class rank was 76th out of 85 students, matching the claim. The third answer confirms that Biden was indeed a student at Syracuse University in the 1960s, specifically in 1968.\"}],\n",
              " 'True',\n",
              " \"Claim: Joe Biden graduated 76th out of 85 students at Syracuse University College of Law in 1968.\\nReasoning: The answers to all three questions support the claim. The first answer confirms that Joe Biden graduated from Syracuse University College of Law in 1968. The second answer states that Biden's class rank was 76th out of 85 students, matching the claim. The third answer confirms that Biden was indeed a student at Syracuse University in the 1960s, specifically in 1968.\\n\")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fact_check_samples[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([''],\n",
              " [{'claim': 'Only two presidents in American history left office with fewer jobs created during their tenure. They were Herbert Hoover and Donald Trump.',\n",
              "   'qa-pairs': {'questions': ['Which presidents left office with the fewest jobs created?',\n",
              "     'Did Herbert Hoover leave office with fewer jobs than when he entered?',\n",
              "     'Did Donald Trump leave office with fewer jobs than when he took office?'],\n",
              "    'answers': ['The presidents who left office with the fewest jobs created were Herbert Hoover and Donald Trump.',\n",
              "     'Yes, Herbert Hoover left office with fewer jobs than when he entered, during the Great Depression.',\n",
              "     'Yes, Donald Trump left office with fewer jobs than when he took office.'],\n",
              "    'sources': ['[\\n    {\\n        \"text\": \"As of 2022, former President Bill Clinton was the president who created the most jobs in the United States, at 18.6 million jobs created ...\",\\n        \"url\": \"https://www.statista.com/statistics/985577/number-jobs-created-sitting-president/\",\\n        \"date_published\": \"Nov 7, 2023\"\\n    },\\n    {\\n        \"text\": \"Jobs were eliminated in almost every sector. Up until the pandemic Trump had unemployment rates at a 50-year low. But I rather think you know ...\",\\n        \"url\": \"https://www.quora.com/Are-you-amazed-that-only-2-US-presidents-have-left-office-with-fewer-jobs-in-the-country-than-when-they-entered-office-the-first-being-Herbert-Hoover-and-the-second-Donald-Trump\",\\n        \"date_published\": \"Sep 15, 2023\"\\n    },\\n    {\\n        \"text\": \"A post calling Trump the \\\\\"worst jobs president\\\\\" holds true based on nonfarm payroll data compared across 13 presidencies.\",\\n        \"url\": \"https://www.usatoday.com/story/news/factcheck/2020/11/06/fact-check-pandemic-unaccounted-presidential-job-growth-chart/6177339002/\",\\n        \"date_published\": \"Nov 6, 2020\"\\n    },\\n    {\\n        \"text\": \"The U.S. has three million fewer jobs than it did when Trump took office. Economists blame both the pandemic and the president\\'s ineffective ...\",\\n        \"url\": \"https://www.washingtonpost.com/business/2021/01/08/trump-jobs-record/\",\\n        \"date_published\": \"Jan 8, 2021\"\\n    },\\n    {\\n        \"text\": \"The final employment scorecard delivered during President Donald Trump\\'s administration on Friday handed the Republican a mantle no ...\",\\n        \"url\": \"https://www.reuters.com/article/idUSKBN29D31G/\",\\n        \"date_published\": \"Jan 8, 2021\"\\n    }\\n]',\n",
              "     '[\\n    {\\n        \"text\": \"He has become the first president since Herbert Hoover during the Great Depression to depart office with fewer jobs in the country than when ...\",\\n        \"url\": \"https://abcnews.go.com/Business/trumps-economic-legacy/story?id=74760051\",\\n        \"date_published\": \"Jan 20, 2021\"\\n    },\\n    {\\n        \"text\": \"The 1920s were a period of optimism and prosperity – for some Americans. When Herbert Hoover became President in 1929, the stock market was climbing to ...\",\\n        \"url\": \"https://hoover.archives.gov/exhibits/great-depression\",\\n        \"date_published\": null\\n    },\\n    {\\n        \"text\": \"Trump has the worst jobs record of any president since Herbert Hoover in 1933.\",\\n        \"url\": \"https://www.newsweek.com/trump-leaving-office-3m-less-jobs-when-he-entered-worst-record-since-depression-1562737\",\\n        \"date_published\": \"Jan 19, 2021\"\\n    },\\n    {\\n        \"text\": \"Jobs were eliminated in almost every sector. Up until the pandemic Trump had unemployment rates at a 50-year low. But I rather think you know ...\",\\n        \"url\": \"https://www.quora.com/Are-you-amazed-that-only-2-US-presidents-have-left-office-with-fewer-jobs-in-the-country-than-when-they-entered-office-the-first-being-Herbert-Hoover-and-the-second-Donald-Trump\",\\n        \"date_published\": \"Sep 15, 2023\"\\n    },\\n    {\\n        \"text\": \"A post calling Trump the \\\\\"worst jobs president\\\\\" holds true based on nonfarm payroll data compared across 13 presidencies.\",\\n        \"url\": \"https://www.usatoday.com/story/news/factcheck/2020/11/06/fact-check-pandemic-unaccounted-presidential-job-growth-chart/6177339002/\",\\n        \"date_published\": \"Nov 6, 2020\"\\n    }\\n]',\n",
              "     '[\\n    {\\n        \"text\": \"The U.S. has three million fewer jobs than it did when Trump took office. Economists blame both the pandemic and the president\\'s ineffective ...\",\\n        \"url\": \"https://www.washingtonpost.com/business/2021/01/08/trump-jobs-record/\",\\n        \"date_published\": \"Jan 8, 2021\"\\n    },\\n    {\\n        \"text\": \"He has become the first president since Herbert Hoover during the Great Depression to depart office with fewer jobs in the country than when ...\",\\n        \"url\": \"https://abcnews.go.com/Business/trumps-economic-legacy/story?id=74760051\",\\n        \"date_published\": \"Jan 20, 2021\"\\n    },\\n    {\\n        \"text\": \"Jobs were eliminated in almost every sector. Up until the pandemic Trump had unemployment rates at a 50-year low. But I rather think you know ...\",\\n        \"url\": \"https://www.quora.com/Are-you-amazed-that-only-2-US-presidents-have-left-office-with-fewer-jobs-in-the-country-than-when-they-entered-office-the-first-being-Herbert-Hoover-and-the-second-Donald-Trump\",\\n        \"date_published\": \"Sep 15, 2023\"\\n    },\\n    {\\n        \"text\": \"A post calling Trump the \\\\\"worst jobs president\\\\\" holds true based on nonfarm payroll data compared across 13 presidencies.\",\\n        \"url\": \"https://www.usatoday.com/story/news/factcheck/2020/11/06/fact-check-pandemic-unaccounted-presidential-job-growth-chart/6177339002/\",\\n        \"date_published\": \"Nov 6, 2020\"\\n    }\\n]']},\n",
              "   'verdict': '',\n",
              "   'reasoning': ''}],\n",
              " 'Unverifiable',\n",
              " 'Claim: Only two presidents in American history left office with fewer jobs created during their tenure. They were Herbert Hoover and Donald Trump.\\nReasoning: \\n')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fact_check_samples.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(save_filename, 'wb') as f:\n",
        "    pickle.dump(fact_check_samples, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verdicts</th>\n",
              "      <th>fact_score</th>\n",
              "      <th>output</th>\n",
              "      <th>reasonings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'The National Guard typically gets ...</td>\n",
              "      <td>Claim: The National Guard typically gets calle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'On Jan. 6, 2021, U.S. Capitol prot...</td>\n",
              "      <td>Claim: On Jan. 6, 2021, U.S. Capitol protestor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'Not even one rocket from Iran hit ...</td>\n",
              "      <td>Claim: Not even one rocket from Iran hit Israe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[False, False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': '326,000 migrants were flown to Flo...</td>\n",
              "      <td>Claim: 326,000 migrants were flown to Florida ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[False, Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'Crime in Venezuela is down by 67%....</td>\n",
              "      <td>Claim: Crime in Venezuela is down by 67%.\\nRea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[False, Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'In New York, there are no barriers...</td>\n",
              "      <td>Claim: In New York, there are no barriers for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[Unverifiable, True]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'The average salary in the semicond...</td>\n",
              "      <td>Claim: The average salary in the semiconductor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Starting in 2025, Medicare Part D ...</td>\n",
              "      <td>Claim: Starting in 2025, Medicare Part D users...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[Unverifiable, True]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'Tens of thousands of auto jobs wer...</td>\n",
              "      <td>Claim: Tens of thousands of auto jobs were los...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'The current Congress is 'the least...</td>\n",
              "      <td>Claim: The current Congress is 'the least prod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'A video shows New York Governor Ka...</td>\n",
              "      <td>Claim: A video shows New York Governor Kathy H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'We've had 12 elections in 24 years...</td>\n",
              "      <td>Claim: We've had 12 elections in 24 years in W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'After a 2022 law, the vast majorit...</td>\n",
              "      <td>Claim: After a 2022 law, the vast majority of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[Unverifiable, Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'Insulin for Medicare beneficiaries...</td>\n",
              "      <td>Claim: Insulin for Medicare beneficiaries was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'Support for Roe is higher today in...</td>\n",
              "      <td>Claim: Support for Roe is higher today in Amer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'The 2022 CHIPS and Science Act att...</td>\n",
              "      <td>Claim: The 2022 CHIPS and Science Act attracte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'It is a fact that Obama created IS...</td>\n",
              "      <td>Claim: It is a fact that Obama created ISIS.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[True, False, True]</td>\n",
              "      <td>Mostly True</td>\n",
              "      <td>[{'claim': 'Millions of Arizonans will soon li...</td>\n",
              "      <td>Claim: Millions of Arizonans will soon live un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>Mostly True</td>\n",
              "      <td>[{'claim': 'Gretchen Whitmer is handing out $5...</td>\n",
              "      <td>Claim: Gretchen Whitmer is handing out $500 a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Rep. Adam Schiff just voted to sen...</td>\n",
              "      <td>Claim: Rep. Adam Schiff just voted to send $10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[True, True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'There are many things Donald Trump...</td>\n",
              "      <td>Claim: There are many things Donald Trump has ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[True, Unverifiable, True, False, True, True, ...</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'Pharmaceutical medicine has its pl...</td>\n",
              "      <td>Claim: Pharmaceutical medicine has its place.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Former U.S. President Donald Trump...</td>\n",
              "      <td>Claim: Former U.S. President Donald Trump stat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Billionaire investor and philanthr...</td>\n",
              "      <td>Claim: Billionaire investor and philanthropist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'President Donald Trump told TIME M...</td>\n",
              "      <td>Claim: President Donald Trump told TIME Magazi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[Unverifiable, True]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'Joe Biden graduated 76th academica...</td>\n",
              "      <td>Claim: Joe Biden graduated 76th academically i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Only two presidents in American hi...</td>\n",
              "      <td>Claim: Only two presidents in American history...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'The top donor to a major super PAC...</td>\n",
              "      <td>Claim: The top donor to a major super PAC supp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'If I don’t get elected, it’s going...</td>\n",
              "      <td>Claim: If I don’t get elected, it’s going to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'U.S. President Joe Biden is the fi...</td>\n",
              "      <td>Claim: U.S. President Joe Biden is the first p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'In February 2024, Nikki Haley lost...</td>\n",
              "      <td>Claim: In February 2024, Nikki Haley lost the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'U.S. President Joe Biden is the on...</td>\n",
              "      <td>Claim: U.S. President Joe Biden is the only pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'Former U.S. President Donald Trump...</td>\n",
              "      <td>Claim: Former U.S. President Donald Trump is t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'Former U.S. President Donald Trump...</td>\n",
              "      <td>Claim: Former U.S. President Donald Trump's ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'U.S. Republican 2024 presidential ...</td>\n",
              "      <td>Claim: U.S. Republican 2024 presidential candi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'You may have had to cancel or reth...</td>\n",
              "      <td>Claim: You may have had to cancel or rethink a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[False, False, Unverifiable, True]</td>\n",
              "      <td>Mostly False</td>\n",
              "      <td>[{'claim': 'Unlike the Democrats, I will not a...</td>\n",
              "      <td>Claim: Unlike the Democrats, I will not allow ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[True, True, Unverifiable, True, Unverifiable,...</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'President Biden did not create the...</td>\n",
              "      <td>Claim: President Biden did not create the bord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[True, True, True, False, False, True]</td>\n",
              "      <td>Mostly True</td>\n",
              "      <td>[{'claim': 'Iran fired and hit one of our dron...</td>\n",
              "      <td>Claim: Iran fired and hit one of our drones.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[False, False, False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'There are one thousand billionaire...</td>\n",
              "      <td>Claim: There are one thousand billionaires in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[Unverifiable, False, Unverifiable, True, False]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'We had the best unemployment rates...</td>\n",
              "      <td>Claim: We had the best unemployment rates ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[True, Unverifiable, True]</td>\n",
              "      <td>Mostly True</td>\n",
              "      <td>[{'claim': 'House Republicans took numerous vo...</td>\n",
              "      <td>Claim: House Republicans took numerous votes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[Unverifiable, True]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'We didn’t sell any land to the Chi...</td>\n",
              "      <td>Claim: We didn’t sell any land to the Chinese....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[True, Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'The climate change agenda is descr...</td>\n",
              "      <td>Claim: The climate change agenda is described ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[True, True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Biological boys are in girls' lock...</td>\n",
              "      <td>Claim: Biological boys are in girls' locker ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[Unverifiable, True]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'China’s eyes and ears are dangerou...</td>\n",
              "      <td>Claim: China’s eyes and ears are dangerously c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[True]</td>\n",
              "      <td>True</td>\n",
              "      <td>[{'claim': 'Hundreds of people on our terroris...</td>\n",
              "      <td>Claim: Hundreds of people on our terrorist wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[False]</td>\n",
              "      <td>Pants on Fire</td>\n",
              "      <td>[{'claim': 'This trial that I have now is refe...</td>\n",
              "      <td>Claim: This trial that I have now is referred ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[Unverifiable, Unverifiable]</td>\n",
              "      <td>Unverifiable</td>\n",
              "      <td>[{'claim': 'President Biden is the first candi...</td>\n",
              "      <td>Claim: President Biden is the first candidate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[True, Unverifiable, True, True, True, True, T...</td>\n",
              "      <td>Mostly True</td>\n",
              "      <td>[{'claim': 'Dollar Tree has had mass store clo...</td>\n",
              "      <td>Claim: Dollar Tree has had mass store closures...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             verdicts     fact_score  \\\n",
              "0                                        [True, True]           True   \n",
              "1                                             [False]  Pants on Fire   \n",
              "2                                             [False]  Pants on Fire   \n",
              "3                                      [False, False]  Pants on Fire   \n",
              "4                               [False, Unverifiable]   Unverifiable   \n",
              "5                               [False, Unverifiable]   Unverifiable   \n",
              "6                                [Unverifiable, True]   Unverifiable   \n",
              "7                                        [True, True]           True   \n",
              "8                                [Unverifiable, True]   Unverifiable   \n",
              "9                                              [True]           True   \n",
              "10                                             [True]           True   \n",
              "11                                     [Unverifiable]   Unverifiable   \n",
              "12                                            [False]  Pants on Fire   \n",
              "13                       [Unverifiable, Unverifiable]   Unverifiable   \n",
              "14                                            [False]  Pants on Fire   \n",
              "15                                            [False]  Pants on Fire   \n",
              "16                                            [False]  Pants on Fire   \n",
              "17                                [True, False, True]    Mostly True   \n",
              "18  [True, True, True, True, True, True, True, Tru...    Mostly True   \n",
              "19                                       [True, True]           True   \n",
              "20                                 [True, True, True]           True   \n",
              "21  [True, Unverifiable, True, False, True, True, ...   Unverifiable   \n",
              "22                                             [True]           True   \n",
              "23                                             [True]           True   \n",
              "24                                            [False]  Pants on Fire   \n",
              "25                               [Unverifiable, True]   Unverifiable   \n",
              "26                                       [True, True]           True   \n",
              "27                                             [True]           True   \n",
              "28                                     [Unverifiable]   Unverifiable   \n",
              "29                                     [Unverifiable]   Unverifiable   \n",
              "30                                       [True, True]           True   \n",
              "31                                     [Unverifiable]   Unverifiable   \n",
              "32                                     [Unverifiable]   Unverifiable   \n",
              "33                                            [False]  Pants on Fire   \n",
              "34                                             [True]           True   \n",
              "35                                       [True, True]           True   \n",
              "36                 [False, False, Unverifiable, True]   Mostly False   \n",
              "37  [True, True, Unverifiable, True, Unverifiable,...   Unverifiable   \n",
              "38             [True, True, True, False, False, True]    Mostly True   \n",
              "39                              [False, False, False]  Pants on Fire   \n",
              "40   [Unverifiable, False, Unverifiable, True, False]   Unverifiable   \n",
              "41                         [True, Unverifiable, True]    Mostly True   \n",
              "42                               [Unverifiable, True]   Unverifiable   \n",
              "43                               [True, Unverifiable]   Unverifiable   \n",
              "44                                       [True, True]           True   \n",
              "45                               [Unverifiable, True]   Unverifiable   \n",
              "46                                             [True]           True   \n",
              "47                                            [False]  Pants on Fire   \n",
              "48                       [Unverifiable, Unverifiable]   Unverifiable   \n",
              "49  [True, Unverifiable, True, True, True, True, T...    Mostly True   \n",
              "\n",
              "                                               output  \\\n",
              "0   [{'claim': 'The National Guard typically gets ...   \n",
              "1   [{'claim': 'On Jan. 6, 2021, U.S. Capitol prot...   \n",
              "2   [{'claim': 'Not even one rocket from Iran hit ...   \n",
              "3   [{'claim': '326,000 migrants were flown to Flo...   \n",
              "4   [{'claim': 'Crime in Venezuela is down by 67%....   \n",
              "5   [{'claim': 'In New York, there are no barriers...   \n",
              "6   [{'claim': 'The average salary in the semicond...   \n",
              "7   [{'claim': 'Starting in 2025, Medicare Part D ...   \n",
              "8   [{'claim': 'Tens of thousands of auto jobs wer...   \n",
              "9   [{'claim': 'The current Congress is 'the least...   \n",
              "10  [{'claim': 'A video shows New York Governor Ka...   \n",
              "11  [{'claim': 'We've had 12 elections in 24 years...   \n",
              "12  [{'claim': 'After a 2022 law, the vast majorit...   \n",
              "13  [{'claim': 'Insulin for Medicare beneficiaries...   \n",
              "14  [{'claim': 'Support for Roe is higher today in...   \n",
              "15  [{'claim': 'The 2022 CHIPS and Science Act att...   \n",
              "16  [{'claim': 'It is a fact that Obama created IS...   \n",
              "17  [{'claim': 'Millions of Arizonans will soon li...   \n",
              "18  [{'claim': 'Gretchen Whitmer is handing out $5...   \n",
              "19  [{'claim': 'Rep. Adam Schiff just voted to sen...   \n",
              "20  [{'claim': 'There are many things Donald Trump...   \n",
              "21  [{'claim': 'Pharmaceutical medicine has its pl...   \n",
              "22  [{'claim': 'Former U.S. President Donald Trump...   \n",
              "23  [{'claim': 'Billionaire investor and philanthr...   \n",
              "24  [{'claim': 'President Donald Trump told TIME M...   \n",
              "25  [{'claim': 'Joe Biden graduated 76th academica...   \n",
              "26  [{'claim': 'Only two presidents in American hi...   \n",
              "27  [{'claim': 'The top donor to a major super PAC...   \n",
              "28  [{'claim': 'If I don’t get elected, it’s going...   \n",
              "29  [{'claim': 'U.S. President Joe Biden is the fi...   \n",
              "30  [{'claim': 'In February 2024, Nikki Haley lost...   \n",
              "31  [{'claim': 'U.S. President Joe Biden is the on...   \n",
              "32  [{'claim': 'Former U.S. President Donald Trump...   \n",
              "33  [{'claim': 'Former U.S. President Donald Trump...   \n",
              "34  [{'claim': 'U.S. Republican 2024 presidential ...   \n",
              "35  [{'claim': 'You may have had to cancel or reth...   \n",
              "36  [{'claim': 'Unlike the Democrats, I will not a...   \n",
              "37  [{'claim': 'President Biden did not create the...   \n",
              "38  [{'claim': 'Iran fired and hit one of our dron...   \n",
              "39  [{'claim': 'There are one thousand billionaire...   \n",
              "40  [{'claim': 'We had the best unemployment rates...   \n",
              "41  [{'claim': 'House Republicans took numerous vo...   \n",
              "42  [{'claim': 'We didn’t sell any land to the Chi...   \n",
              "43  [{'claim': 'The climate change agenda is descr...   \n",
              "44  [{'claim': 'Biological boys are in girls' lock...   \n",
              "45  [{'claim': 'China’s eyes and ears are dangerou...   \n",
              "46  [{'claim': 'Hundreds of people on our terroris...   \n",
              "47  [{'claim': 'This trial that I have now is refe...   \n",
              "48  [{'claim': 'President Biden is the first candi...   \n",
              "49  [{'claim': 'Dollar Tree has had mass store clo...   \n",
              "\n",
              "                                           reasonings  \n",
              "0   Claim: The National Guard typically gets calle...  \n",
              "1   Claim: On Jan. 6, 2021, U.S. Capitol protestor...  \n",
              "2   Claim: Not even one rocket from Iran hit Israe...  \n",
              "3   Claim: 326,000 migrants were flown to Florida ...  \n",
              "4   Claim: Crime in Venezuela is down by 67%.\\nRea...  \n",
              "5   Claim: In New York, there are no barriers for ...  \n",
              "6   Claim: The average salary in the semiconductor...  \n",
              "7   Claim: Starting in 2025, Medicare Part D users...  \n",
              "8   Claim: Tens of thousands of auto jobs were los...  \n",
              "9   Claim: The current Congress is 'the least prod...  \n",
              "10  Claim: A video shows New York Governor Kathy H...  \n",
              "11  Claim: We've had 12 elections in 24 years in W...  \n",
              "12  Claim: After a 2022 law, the vast majority of ...  \n",
              "13  Claim: Insulin for Medicare beneficiaries was ...  \n",
              "14  Claim: Support for Roe is higher today in Amer...  \n",
              "15  Claim: The 2022 CHIPS and Science Act attracte...  \n",
              "16  Claim: It is a fact that Obama created ISIS.\\n...  \n",
              "17  Claim: Millions of Arizonans will soon live un...  \n",
              "18  Claim: Gretchen Whitmer is handing out $500 a ...  \n",
              "19  Claim: Rep. Adam Schiff just voted to send $10...  \n",
              "20  Claim: There are many things Donald Trump has ...  \n",
              "21  Claim: Pharmaceutical medicine has its place.\\...  \n",
              "22  Claim: Former U.S. President Donald Trump stat...  \n",
              "23  Claim: Billionaire investor and philanthropist...  \n",
              "24  Claim: President Donald Trump told TIME Magazi...  \n",
              "25  Claim: Joe Biden graduated 76th academically i...  \n",
              "26  Claim: Only two presidents in American history...  \n",
              "27  Claim: The top donor to a major super PAC supp...  \n",
              "28  Claim: If I don’t get elected, it’s going to b...  \n",
              "29  Claim: U.S. President Joe Biden is the first p...  \n",
              "30  Claim: In February 2024, Nikki Haley lost the ...  \n",
              "31  Claim: U.S. President Joe Biden is the only pr...  \n",
              "32  Claim: Former U.S. President Donald Trump is t...  \n",
              "33  Claim: Former U.S. President Donald Trump's ma...  \n",
              "34  Claim: U.S. Republican 2024 presidential candi...  \n",
              "35  Claim: You may have had to cancel or rethink a...  \n",
              "36  Claim: Unlike the Democrats, I will not allow ...  \n",
              "37  Claim: President Biden did not create the bord...  \n",
              "38  Claim: Iran fired and hit one of our drones.\\n...  \n",
              "39  Claim: There are one thousand billionaires in ...  \n",
              "40  Claim: We had the best unemployment rates ever...  \n",
              "41  Claim: House Republicans took numerous votes t...  \n",
              "42  Claim: We didn’t sell any land to the Chinese....  \n",
              "43  Claim: The climate change agenda is described ...  \n",
              "44  Claim: Biological boys are in girls' locker ro...  \n",
              "45  Claim: China’s eyes and ears are dangerously c...  \n",
              "46  Claim: Hundreds of people on our terrorist wat...  \n",
              "47  Claim: This trial that I have now is referred ...  \n",
              "48  Claim: President Biden is the first candidate ...  \n",
              "49  Claim: Dollar Tree has had mass store closures...  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hugchat_sample = pd.DataFrame({\n",
        "    \"verdicts\": [x[0] for x in fact_check_samples],\n",
        "    \"fact_score\": [x[2] for x in fact_check_samples],\n",
        "    \"output\": [x[1] for x in fact_check_samples],\n",
        "    \"reasonings\": [x[3] for x in fact_check_samples]\n",
        "})\n",
        "hugchat_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNRmJd1Jsxj6"
      },
      "outputs": [],
      "source": [
        "# Save the results to an Excel file\n",
        "filename = 'final-gpt-4-turbo-samples.xlsx'\n",
        "full_path = os.path.join(base_dir, filename)\n",
        "hugchat_sample.to_excel(full_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
